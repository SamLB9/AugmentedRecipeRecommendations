{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/meettyj/RecipeRec.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUEvZZaPoTvl",
        "outputId": "75a4243a-3465-4596-d17b-7c48669b6e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RecipeRec'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 11 (delta 2), reused 6 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (11/11), 26.97 KiB | 13.49 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/data_mlp_project/ /content/data"
      ],
      "metadata": {
        "id": "PVainBRSnLSi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGhT_KlloGRG",
        "outputId": "a28eec57-438e-4818-9df0-2876b67e32ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 10 19:01:28 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "import platform\n",
        "print(platform.platform())\n",
        "print(platform.system(), platform.release())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_VSAk4vpBLd",
        "outputId": "eaf65959-9ace-4810-b4c5-fcf1dcdd81d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n",
            "12.4\n",
            "Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "Linux 6.1.85+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b7ZA3GqRpOcf",
        "outputId": "bfec75c1-5908-4ec9-ab29-82133056641a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/torch-2.4/cu124/dgl-2.4.0%2Bcu124-cp311-cp311-manylinux1_x86_64.whl (347.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from dgl) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from dgl) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from dgl) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl) (4.67.1)\n",
            "Collecting torch<=2.4.0 (from dgl)\n",
            "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dgl) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dgl) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (3.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch<=2.4.0->dgl)\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.5.82)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->dgl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->dgl) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->dgl) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<=2.4.0->dgl) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
            "Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, dgl\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.4.0 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dgl-2.4.0+cu124 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 triton-3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "a2ab7ff688c14fea95ae28264bf0bb31"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P_sWCFhp_dr",
        "outputId": "3178ae86-65d3-4cff-a8bc-cbe9bc35addb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torchfile\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5693 sha256=72c83c2c90c0cf41b715cfeac996e5d6446ee53a6012f2a2edf1702ad4645b16\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/0d/6c/cc20d113923479bc37343fc2268b9b369a1b25a4cb97296b3a\n",
            "Successfully built torchfile\n",
            "Installing collected packages: torchfile\n",
            "Successfully installed torchfile-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lmdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etqCOnfZsDB4",
        "outputId": "9106bca0-cbf5-4170-8685-f26a481c2c96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lmdb\n",
            "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/297.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m297.0/297.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lmdb\n",
            "Successfully installed lmdb-1.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import re\n",
        "import nltk\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import random\n",
        "import heapq\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import lmdb\n",
        "import gensim\n",
        "import heapq\n",
        "os.environ[\"DGL_GRAPHBOLT_DISABLE\"] = \"1\"\n",
        "\n",
        "import dgl\n",
        "import dgl.nn as dglnn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl.nn.functional import edge_softmax\n",
        "import torchfile\n",
        "from torch.nn import init\n",
        "import dgl.function as fn\n",
        "from dgl.utils import expand_as_pair\n",
        "from dgl.nn import EdgeWeightNorm\n",
        "from dgl.distributed import DistDataLoader\n",
        "from dgl.distributed.dist_dataloader import EdgeCollator\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "Nn8RsJBvoIOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc19221-7d09-43fa-db7f-9a3f7458420f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dgl/graphbolt/__init__.py:114: GBWarning: \n",
            "An experimental feature for CUDA allocations is turned on for better allocation\n",
            "pattern resulting in better memory usage for minibatch GNN training workloads.\n",
            "See https://pytorch.org/docs/stable/notes/cuda.html#optimizing-memory-usage-with-pytorch-cuda-alloc-conf,\n",
            "and set the environment variable `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:False`\n",
            "if you want to disable it and set it True to acknowledge and disable the warning.\n",
            "\n",
            "  gb_warning(WARNING_STR_TO_BE_SHOWN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device: ', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKcqpG-aqGfU",
        "outputId": "2559c67e-2dfa-4111-fa12-41923fba5b3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device:  cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "Ks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # top@K performance\n",
        "n_test_negs = 100 # number of negative recipes for each test user\n",
        "dataset_folder = '/content/data'"
      ],
      "metadata": {
        "id": "JLVDqQhBqOfQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build graph"
      ],
      "metadata": {
        "id": "PAc2fMBwrsDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph():\n",
        "    print('generating graph ...')\n",
        "    edge_src, edge_dst, r_i_edge_weight = torch.load(dataset_folder+'/edge_r2i_src_dst_weight.pt')\n",
        "    recipe_edge_src, recipe_edge_dst, recipe_edge_weight = torch.load(dataset_folder+'/edge_r2r_src_and_dst_and_weight.pt')\n",
        "    ingre_edge_src, ingre_edge_dst, ingre_edge_weight = torch.load(dataset_folder+'/edge_i2i_src_and_dst_and_weight.pt')\n",
        "    all_u2r_src_dst_weight, train_u2r_src_dst_weight, val_u2r_src_dst_weight, test_u2r_src_dst_weight = torch.load(dataset_folder+'/all_train_val_test_edge_u_rate_r_src_and_dst_and_weight.pt')\n",
        "    u_rate_r_edge_src, u_rate_r_edge_dst, u_rate_r_edge_weight = all_u2r_src_dst_weight\n",
        "\n",
        "    # nodes and edges\n",
        "    graph = dgl.heterograph({\n",
        "        ('recipe', 'r-i', 'ingredient'): (edge_src, edge_dst),\n",
        "        ('ingredient', 'i-r', 'recipe'): (edge_dst, edge_src),\n",
        "        ('recipe', 'r-r', 'recipe'): (recipe_edge_src, recipe_edge_dst),\n",
        "        ('ingredient', 'i-i', 'ingredient'): (ingre_edge_src, ingre_edge_dst),\n",
        "        ('user', 'u-r', 'recipe'): (u_rate_r_edge_src, u_rate_r_edge_dst),\n",
        "        ('recipe', 'r-u', 'user'): (u_rate_r_edge_dst, u_rate_r_edge_src)\n",
        "    })\n",
        "\n",
        "    metapaths = {\n",
        "    'recipe-ingredient-recipe': [('recipe', 'r-i', 'ingredient'), ('ingredient', 'i-r', 'recipe')],\n",
        "    'user-recipe-user': [('user', 'u-r', 'recipe'), ('recipe', 'r-u', 'user')],\n",
        "    'recipe-recipe': [('recipe', 'r-r', 'recipe')],\n",
        "    'ingredient-ingredient': [('ingredient', 'i-i', 'ingredient')]\n",
        "    }\n",
        "    graph.metapaths = metapaths\n",
        "\n",
        "    # edge weight\n",
        "    graph.edges['r-i'].data['weight'] = torch.FloatTensor(r_i_edge_weight)\n",
        "    graph.edges['i-r'].data['weight'] = torch.FloatTensor(r_i_edge_weight)\n",
        "    graph.edges['r-r'].data['weight'] = torch.FloatTensor(recipe_edge_weight)\n",
        "    graph.edges['i-i'].data['weight'] = torch.FloatTensor(ingre_edge_weight)\n",
        "    graph.edges['u-r'].data['weight'] = torch.FloatTensor(u_rate_r_edge_weight)\n",
        "    graph.edges['r-u'].data['weight'] = torch.FloatTensor(u_rate_r_edge_weight)\n",
        "\n",
        "    # node features\n",
        "    recipe_nodes_avg_instruction_features = torch.load(dataset_folder+'/recipe_nodes_avg_instruction_features.pt')\n",
        "    ingredient_nodes_nutrient_features_minus1 = torch.load(dataset_folder+'/ingredient_nodes_nutrient_features.pt')\n",
        "    graph.nodes['recipe'].data['avg_instr_feature'] = recipe_nodes_avg_instruction_features\n",
        "    graph.nodes['ingredient'].data['nutrient_feature'] = ingredient_nodes_nutrient_features_minus1\n",
        "    graph.nodes['user'].data['random_feature'] = torch.nn.init.xavier_normal_(torch.ones(7959, 300))\n",
        "    graph.nodes['recipe'].data['random_feature'] = torch.nn.init.xavier_normal_(torch.ones(68794, 1024))\n",
        "\n",
        "    return graph\n",
        "\n",
        "graph = get_graph()\n",
        "print('graph: ', graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GNDWUklqSjx",
        "outputId": "3aceb3c5-61e8-4e0b-b0df-5973681b0953"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generating graph ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-e236fe1c4574>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  edge_src, edge_dst, r_i_edge_weight = torch.load(dataset_folder+'/edge_r2i_src_dst_weight.pt')\n",
            "<ipython-input-8-e236fe1c4574>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  recipe_edge_src, recipe_edge_dst, recipe_edge_weight = torch.load(dataset_folder+'/edge_r2r_src_and_dst_and_weight.pt')\n",
            "<ipython-input-8-e236fe1c4574>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ingre_edge_src, ingre_edge_dst, ingre_edge_weight = torch.load(dataset_folder+'/edge_i2i_src_and_dst_and_weight.pt')\n",
            "<ipython-input-8-e236fe1c4574>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  all_u2r_src_dst_weight, train_u2r_src_dst_weight, val_u2r_src_dst_weight, test_u2r_src_dst_weight = torch.load(dataset_folder+'/all_train_val_test_edge_u_rate_r_src_and_dst_and_weight.pt')\n",
            "<ipython-input-8-e236fe1c4574>:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  recipe_nodes_avg_instruction_features = torch.load(dataset_folder+'/recipe_nodes_avg_instruction_features.pt')\n",
            "<ipython-input-8-e236fe1c4574>:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ingredient_nodes_nutrient_features_minus1 = torch.load(dataset_folder+'/ingredient_nodes_nutrient_features.pt')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph:  Graph(num_nodes={'ingredient': 8847, 'recipe': 68794, 'user': 7959},\n",
            "      num_edges={('ingredient', 'i-i', 'ingredient'): 146188, ('ingredient', 'i-r', 'recipe'): 463485, ('recipe', 'r-i', 'ingredient'): 463485, ('recipe', 'r-r', 'recipe'): 647146, ('recipe', 'r-u', 'user'): 135353, ('user', 'u-r', 'recipe'): 135353},\n",
            "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split train/val/test"
      ],
      "metadata": {
        "id": "Av-gsp2lrvs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_src_dst_weight, train_src_dst_weight, val_src_dst_weight, test_src_dst_weight = torch.load(dataset_folder+'/all_train_val_test_edge_u_rate_r_src_and_dst_and_weight.pt')\n",
        "all_src, all_dst, all_weight = all_src_dst_weight\n",
        "train_src, train_dst, train_weight = train_src_dst_weight\n",
        "val_src, val_dst, val_weight = val_src_dst_weight\n",
        "test_src, test_dst, test_weight = test_src_dst_weight\n",
        "\n",
        "train_eids = graph.edge_ids(train_src, train_dst, etype='u-r')\n",
        "val_eids = graph.edge_ids(val_src, val_dst, etype='u-r')\n",
        "test_eids = graph.edge_ids(test_src, test_dst, etype='u-r')\n",
        "val_eids_r2u = graph.edge_ids(val_dst, val_src, etype='r-u')\n",
        "test_eids_r2u = graph.edge_ids(test_dst, test_src, etype='r-u')\n",
        "print('length of all_src: ', len(all_src))\n",
        "print('length of train_eids: ', len(train_eids))\n",
        "print('length of val_eids: ', len(val_eids))\n",
        "print('length of test_eids: ', len(test_eids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zb4XjAAqo8B",
        "outputId": "cc92f21f-df3d-4c9c-f39d-2406eb310ea7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of all_src:  135353\n",
            "length of train_eids:  119435\n",
            "length of val_eids:  7959\n",
            "length of test_eids:  7959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-63b0a4d482de>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  all_src_dst_weight, train_src_dst_weight, val_src_dst_weight, test_src_dst_weight = torch.load(dataset_folder+'/all_train_val_test_edge_u_rate_r_src_and_dst_and_weight.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get train_graph and val_graph\n",
        "train_graph = graph.clone()\n",
        "train_graph.remove_edges(torch.cat([val_eids, test_eids]), etype='u-r')\n",
        "train_graph.remove_edges(torch.cat([val_eids_r2u, test_eids_r2u]), etype='r-u')\n",
        "print('training graph: ')\n",
        "print(train_graph)\n",
        "print()\n",
        "\n",
        "val_graph = graph.clone()\n",
        "val_graph.remove_edges(test_eids, etype='u-r')\n",
        "val_graph.remove_edges(test_eids, etype='r-u')\n",
        "print('val graph: ')\n",
        "print(val_graph)\n",
        "\n",
        "for g in [train_graph, val_graph, graph]:\n",
        "    if not hasattr(g, '_use_graphbolt'):\n",
        "        g._use_graphbolt = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx7tmWe3qurf",
        "outputId": "f7f296cb-ac15-4b0a-ae71-c99cec8020b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training graph: \n",
            "Graph(num_nodes={'ingredient': 8847, 'recipe': 68794, 'user': 7959},\n",
            "      num_edges={('ingredient', 'i-i', 'ingredient'): 146188, ('ingredient', 'i-r', 'recipe'): 463485, ('recipe', 'r-i', 'ingredient'): 463485, ('recipe', 'r-r', 'recipe'): 647146, ('recipe', 'r-u', 'user'): 119435, ('user', 'u-r', 'recipe'): 119435},\n",
            "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])\n",
            "\n",
            "val graph: \n",
            "Graph(num_nodes={'ingredient': 8847, 'recipe': 68794, 'user': 7959},\n",
            "      num_edges={('ingredient', 'i-i', 'ingredient'): 146188, ('ingredient', 'i-r', 'recipe'): 463485, ('recipe', 'r-i', 'ingredient'): 463485, ('recipe', 'r-r', 'recipe'): 647146, ('recipe', 'r-u', 'user'): 127394, ('user', 'u-r', 'recipe'): 127394},\n",
            "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# edge dataloaders\n",
        "sampler = dgl.dataloading.MultiLayerNeighborSampler([20, 20])\n",
        "neg_sampler = dgl.dataloading.negative_sampler.Uniform(5)\n",
        "\n",
        "class test_NegativeSampler(object):\n",
        "    def __init__(self, g, k):\n",
        "        # get the negatives\n",
        "        self.user2negs_100_dict = {}\n",
        "        filename = dataset_folder+'/test_negatives_100.txt'\n",
        "        with open(filename, \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "            for line in tqdm(lines):\n",
        "                if line == None or line == \"\":\n",
        "                    continue\n",
        "                line = line[:-1] # remove \\n\n",
        "                user = int(line.split('\\t')[0].split(',')[0][1:])\n",
        "                negs = [int(neg) for neg in line.split('\\t')[1:]]\n",
        "                self.user2negs_100_dict[user] = negs\n",
        "\n",
        "        self.k = k\n",
        "\n",
        "    def __call__(self, g, eids_dict):\n",
        "        result_dict = {}\n",
        "        for etype, eids in eids_dict.items():\n",
        "            src, _ = g.find_edges(eids, etype=etype)\n",
        "            dst = []\n",
        "            for each_src in src:\n",
        "                dst.extend(self.user2negs_100_dict[int(each_src)][:self.k])\n",
        "            dst = torch.tensor(dst)\n",
        "            src = src.repeat_interleave(self.k)\n",
        "            result_dict[etype] = (src, dst)\n",
        "        return result_dict\n",
        "\n",
        "test_neg_sampler = test_NegativeSampler(graph, n_test_negs)\n",
        "test_train_neg_sampler = test_NegativeSampler(graph, n_test_negs)\n",
        "\n",
        "train_collator = EdgeCollator(\n",
        "    train_graph, {'u-r': train_graph.edge_ids(train_src, train_dst, etype='u-r')}, sampler,\n",
        "    exclude='reverse_types',\n",
        "    reverse_etypes={'u-r': 'r-u', 'r-u': 'u-r'},\n",
        "    negative_sampler=neg_sampler)\n",
        "val_collator = EdgeCollator(\n",
        "    val_graph, {'u-r': val_graph.edge_ids(val_src, val_dst, etype='u-r')}, sampler,\n",
        "    exclude='reverse_types',\n",
        "    reverse_etypes={'u-r': 'r-u', 'r-u': 'u-r'},\n",
        "    negative_sampler=neg_sampler)\n",
        "test_collator = EdgeCollator(\n",
        "    graph, {('user', 'u-r', 'recipe'): test_eids}, sampler,\n",
        "    exclude='reverse_types',\n",
        "    reverse_etypes={'u-r': 'r-u', 'r-u': 'u-r'},\n",
        "    negative_sampler=test_neg_sampler)\n",
        "\n",
        "train_edgeloader = torch.utils.data.DataLoader(\n",
        "    train_collator.dataset, collate_fn=train_collator.collate,\n",
        "    batch_size=1024, shuffle=True, drop_last=False, num_workers=0)\n",
        "val_edgeloader = torch.utils.data.DataLoader(\n",
        "    val_collator.dataset, collate_fn=val_collator.collate,\n",
        "    batch_size=128, shuffle=False, drop_last=False, num_workers=0)\n",
        "test_edgeloader = torch.utils.data.DataLoader(\n",
        "    test_collator.dataset, collate_fn=test_collator.collate,\n",
        "    batch_size=128, shuffle=False, drop_last=False, num_workers=0)\n",
        "\n",
        "print('# of batches in train_edgeloader: ', len(train_edgeloader))\n",
        "print('# of batches in val_edgeloader: ', len(val_edgeloader))\n",
        "print('# of batches in test_edgeloader: ', len(test_edgeloader))\n",
        "print()\n",
        "\n",
        "for input_nodes, pos_pair_graph, neg_pair_graph, blocks in train_edgeloader:\n",
        "    print('blocks: ', blocks)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh9SOI1pqxzM",
        "outputId": "7bce7761-57d2-4039-a855-7e5a4993485a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7959/7959 [00:00<00:00, 22768.23it/s]\n",
            "100%|██████████| 7959/7959 [00:00<00:00, 28873.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of batches in train_edgeloader:  117\n",
            "# of batches in val_edgeloader:  63\n",
            "# of batches in test_edgeloader:  63\n",
            "\n",
            "blocks:  [Block(num_src_nodes={'ingredient': 6530, 'recipe': 61784, 'user': 5805},\n",
            "      num_dst_nodes={'ingredient': 3680, 'recipe': 27127, 'user': 3050},\n",
            "      num_edges={('ingredient', 'i-i', 'ingredient'): 47753, ('ingredient', 'i-r', 'recipe'): 178069, ('recipe', 'r-i', 'ingredient'): 50523, ('recipe', 'r-r', 'recipe'): 252475, ('recipe', 'r-u', 'user'): 35573, ('user', 'u-r', 'recipe'): 52401},\n",
            "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')]), Block(num_src_nodes={'ingredient': 3680, 'recipe': 27127, 'user': 3050},\n",
            "      num_dst_nodes={'ingredient': 0, 'recipe': 5867, 'user': 682},\n",
            "      num_edges={('ingredient', 'i-i', 'ingredient'): 0, ('ingredient', 'i-r', 'recipe'): 39700, ('recipe', 'r-i', 'ingredient'): 0, ('recipe', 'r-r', 'recipe'): 31728, ('recipe', 'r-u', 'user'): 10315, ('user', 'u-r', 'recipe'): 9970},\n",
            "      metagraph=[('ingredient', 'ingredient', 'i-i'), ('ingredient', 'recipe', 'i-r'), ('recipe', 'ingredient', 'r-i'), ('recipe', 'recipe', 'r-r'), ('recipe', 'user', 'r-u'), ('user', 'recipe', 'u-r')])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Transformer"
      ],
      "metadata": {
        "id": "yqa1_2Ldr3QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get ingre neighbors for each recipe nodes\n",
        "def get_recipe2ingreNeighbor_dict():\n",
        "    max_length = 33\n",
        "    out = {}\n",
        "    neighbor_list = []\n",
        "    ingre_length_list = []\n",
        "    total_length_index_list = []\n",
        "    total_ingre_neighbor_list = []\n",
        "    total_length_index = 0\n",
        "    total_length_index_list.append(total_length_index)\n",
        "    for recipeNodeID in tqdm(range(graph.number_of_nodes('recipe'))):\n",
        "        _, succs = graph.out_edges(recipeNodeID, etype='r-i')\n",
        "        succs_list = list(set(succs.tolist()))\n",
        "        total_ingre_neighbor_list.extend(succs_list)\n",
        "        cur_length = len(succs_list)\n",
        "        ingre_length_list.append(cur_length)\n",
        "\n",
        "        total_length_index += cur_length\n",
        "        total_length_index_list.append(total_length_index)\n",
        "        while len(succs_list) < max_length:\n",
        "            succs_list.append(77733)\n",
        "        neighbor_list.append(succs_list)\n",
        "\n",
        "    ingre_neighbor_tensor = torch.tensor(neighbor_list)\n",
        "    ingre_length_tensor = torch.tensor(ingre_length_list)\n",
        "    total_ingre_neighbor_tensor = torch.tensor(total_ingre_neighbor_list)\n",
        "    return ingre_neighbor_tensor, ingre_length_tensor, total_length_index_list, total_ingre_neighbor_tensor\n",
        "\n",
        "ingre_neighbor_tensor, ingre_length_tensor, total_length_index_list, total_ingre_neighbor_tensor = get_recipe2ingreNeighbor_dict()\n",
        "print('ingre_neighbor_tensor: ', ingre_neighbor_tensor.shape)\n",
        "print('ingre_length_tensor: ', ingre_length_tensor.shape)\n",
        "print('total_length_index_list: ', len(total_length_index_list))\n",
        "print('total_ingre_neighbor_tensor: ', total_ingre_neighbor_tensor.shape)\n",
        "\n",
        "def find(tensor, values):\n",
        "    return torch.nonzero(tensor[..., None] == values)\n",
        "\n",
        "# example of find()\n",
        "# a = torch.tensor([0, 10, 20, 30])\n",
        "# b = torch.tensor([[ 0, 30, 20,  10, 77733],[ 0, 30, 20,  10, 77733]])\n",
        "# find(b, a)[:, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7u6c-pXq1MT",
        "outputId": "26f8fd52-cc8e-47a3-f851-584cff126030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 68794/68794 [00:12<00:00, 5299.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ingre_neighbor_tensor:  torch.Size([68794, 33])\n",
            "ingre_length_tensor:  torch.Size([68794])\n",
            "total_length_index_list:  68795\n",
            "total_ingre_neighbor_tensor:  torch.Size([454941])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ingredient_neighbors_all_embeddings(blocks, output_nodes, secondToLast_ingre):\n",
        "    ingreNodeIDs = blocks[1].srcdata['_ID']['ingredient']\n",
        "    recipeNodeIDs = output_nodes\n",
        "    batch_ingre_neighbors = ingre_neighbor_tensor[recipeNodeIDs.cpu()].to(device)\n",
        "    batch_ingre_length = ingre_length_tensor[recipeNodeIDs.cpu()].to(device)\n",
        "    valid_batch_ingre_neighbors = find(batch_ingre_neighbors, ingreNodeIDs)[:, 2]\n",
        "\n",
        "    # based on valid_batch_ingre_neighbors each row index\n",
        "    _, valid_batch_ingre_length = torch.unique(find(batch_ingre_neighbors, ingreNodeIDs)[:, 0], return_counts=True)\n",
        "    batch_sum_ingre_length = np.cumsum(valid_batch_ingre_length.cpu())\n",
        "\n",
        "    total_ingre_emb = None\n",
        "    for i in range(len(recipeNodeIDs)):\n",
        "        if i == 0:\n",
        "            recipeNode_ingres = valid_batch_ingre_neighbors[0:batch_sum_ingre_length[i]]\n",
        "            a = secondToLast_ingre[recipeNode_ingres]\n",
        "        else:\n",
        "            recipeNode_ingres = valid_batch_ingre_neighbors[batch_sum_ingre_length[i-1]:batch_sum_ingre_length[i]]\n",
        "            a = secondToLast_ingre[recipeNode_ingres]\n",
        "\n",
        "        # all ingre instead of average\n",
        "        a_rows = a.shape[0]\n",
        "        a_columns = a.shape[1]\n",
        "        max_rows = 5\n",
        "        if a_rows < max_rows:\n",
        "            a = torch.cat([a, torch.zeros(max_rows-a_rows, a_columns).cuda()])\n",
        "        else:\n",
        "            a = a[:max_rows, :]\n",
        "\n",
        "        if total_ingre_emb == None:\n",
        "            total_ingre_emb = a.unsqueeze(0)\n",
        "        else:\n",
        "            total_ingre_emb = torch.cat([total_ingre_emb,a.unsqueeze(0)], dim = 0)\n",
        "            if torch.isnan(total_ingre_emb).any():\n",
        "                print('Error!')\n",
        "\n",
        "    return total_ingre_emb"
      ],
      "metadata": {
        "id": "eyqEWmxfq6ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    \"\"\"Scaled Dot-Product Attention.\"\"\"\n",
        "\n",
        "    def __init__(self, temperature):\n",
        "        super().__init__()\n",
        "\n",
        "        self.temperature = temperature\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"\n",
        "        It is equivariant to permutations\n",
        "        of the batch dimension (`b`).\n",
        "\n",
        "        It is equivariant to permutations of the\n",
        "        second dimension of the queries (`n`).\n",
        "\n",
        "        It is invariant to permutations of the\n",
        "        second dimension of keys and values (`m`).\n",
        "\n",
        "        Arguments:\n",
        "            queries: a float tensor with shape [b, n, d].\n",
        "            keys: a float tensor with shape [b, m, d].\n",
        "            values: a float tensor with shape [b, m, d'].\n",
        "        Returns:\n",
        "            a float tensor with shape [b, n, d'].\n",
        "        \"\"\"\n",
        "\n",
        "        attention = torch.bmm(queries, keys.transpose(1, 2))\n",
        "        attention = self.softmax(attention / self.temperature)\n",
        "        # it has shape [b, n, m]\n",
        "\n",
        "        return torch.bmm(attention, values)\n",
        "\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d, h):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            d: an integer, dimension of queries and values.\n",
        "                It is assumed that input and\n",
        "                output dimensions are the same.\n",
        "            h: an integer, number of heads.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        assert d % h == 0\n",
        "        self.h = h\n",
        "\n",
        "        # everything is projected to this dimension\n",
        "        p = d // h\n",
        "\n",
        "        self.project_queries = nn.Linear(d, d)\n",
        "        self.project_keys = nn.Linear(d, d)\n",
        "        self.project_values = nn.Linear(d, d)\n",
        "        self.concatenation = nn.Linear(d, d)\n",
        "        self.attention = Attention(temperature=p**0.5)\n",
        "\n",
        "    def forward(self, queries, keys, values):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            queries: a float tensor with shape [b, n, d].\n",
        "            keys: a float tensor with shape [b, m, d].\n",
        "            values: a float tensor with shape [b, m, d].\n",
        "        Returns:\n",
        "            a float tensor with shape [b, n, d].\n",
        "        \"\"\"\n",
        "\n",
        "        h = self.h\n",
        "        b, n, d = queries.size()\n",
        "        _, m, _ = keys.size()\n",
        "        p = d // h\n",
        "\n",
        "        queries = self.project_queries(queries)  # shape [b, n, d]\n",
        "        keys = self.project_keys(keys)  # shape [b, m, d]\n",
        "        values = self.project_values(values)  # shape [b, m, d]\n",
        "\n",
        "        queries = queries.view(b, n, h, p)\n",
        "        keys = keys.view(b, m, h, p)\n",
        "        values = values.view(b, m, h, p)\n",
        "\n",
        "        queries = queries.permute(2, 0, 1, 3).contiguous().view(h * b, n, p)\n",
        "        keys = keys.permute(2, 0, 1, 3).contiguous().view(h * b, m, p)\n",
        "        values = values.permute(2, 0, 1, 3).contiguous().view(h * b, m, p)\n",
        "\n",
        "        output = self.attention(queries, keys, values)  # shape [h * b, n, p]\n",
        "        output = output.view(h, b, n, p)\n",
        "        output = output.permute(1, 2, 0, 3).contiguous().view(b, n, d)\n",
        "        output = self.concatenation(output)  # shape [b, n, d]\n",
        "\n",
        "        return output\n",
        "\n",
        "class RFF(nn.Module):\n",
        "    \"\"\"\n",
        "    Row-wise FeedForward layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, d):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(d, d), nn.ReLU(inplace=True),\n",
        "            nn.Linear(d, d), nn.ReLU(inplace=True),\n",
        "            nn.Linear(d, d), nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: a float tensor with shape [b, n, d].\n",
        "        Returns:\n",
        "            a float tensor with shape [b, n, d].\n",
        "        \"\"\"\n",
        "        return self.layers(x)\n",
        "\n",
        "class MultiheadAttentionBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, d, h, rff):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            d: an integer, input dimension.\n",
        "            h: an integer, number of heads.\n",
        "            rff: a module, row-wise feedforward layers.\n",
        "                It takes a float tensor with shape [b, n, d] and\n",
        "                returns a float tensor with the same shape.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.multihead = MultiheadAttention(d, h)\n",
        "        self.layer_norm1 = nn.LayerNorm(d)\n",
        "        self.layer_norm2 = nn.LayerNorm(d)\n",
        "        self.rff = rff\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \"\"\"\n",
        "        It is equivariant to permutations of the\n",
        "        second dimension of tensor x (`n`).\n",
        "\n",
        "        It is invariant to permutations of the\n",
        "        second dimension of tensor y (`m`).\n",
        "\n",
        "        Arguments:\n",
        "            x: a float tensor with shape [b, n, d].\n",
        "            y: a float tensor with shape [b, m, d].\n",
        "        Returns:\n",
        "            a float tensor with shape [b, n, d].\n",
        "        \"\"\"\n",
        "        h = self.layer_norm1(x + self.multihead(x, y, y))\n",
        "        return self.layer_norm2(h + self.rff(h))\n",
        "\n",
        "class SetAttentionBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, d, h, rff):\n",
        "        super().__init__()\n",
        "        self.mab = MultiheadAttentionBlock(d, h, rff)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: a float tensor with shape [b, n, d].\n",
        "        Returns:\n",
        "            a float tensor with shape [b, n, d].\n",
        "        \"\"\"\n",
        "        return self.mab(x, x)\n",
        "\n",
        "class InducedSetAttentionBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, d, m, h, rff1, rff2):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            d: an integer, input dimension.\n",
        "            m: an integer, number of inducing points.\n",
        "            h: an integer, number of heads.\n",
        "            rff1, rff2: modules, row-wise feedforward layers.\n",
        "                It takes a float tensor with shape [b, n, d] and\n",
        "                returns a float tensor with the same shape.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.mab1 = MultiheadAttentionBlock(d, h, rff1)\n",
        "        self.mab2 = MultiheadAttentionBlock(d, h, rff2)\n",
        "        self.inducing_points = nn.Parameter(torch.randn(1, m, d))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: a float tensor with shape [b, n, d].\n",
        "        Returns:\n",
        "            a float tensor with shape [b, n, d].\n",
        "        \"\"\"\n",
        "        b = x.size(0)\n",
        "        p = self.inducing_points\n",
        "        p = p.repeat([b, 1, 1])  # shape [b, m, d]\n",
        "        h = self.mab1(p, x)  # shape [b, m, d]\n",
        "        return self.mab2(x, h)\n",
        "\n",
        "class PoolingMultiheadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d, k, h, rff):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            d: an integer, input dimension.\n",
        "            k: an integer, number of seed vectors.\n",
        "            h: an integer, number of heads.\n",
        "            rff: a module, row-wise feedforward layers.\n",
        "                It takes a float tensor with shape [b, n, d] and\n",
        "                returns a float tensor with the same shape.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.mab = MultiheadAttentionBlock(d, h, rff)\n",
        "        self.seed_vectors = nn.Parameter(torch.randn(1, k, d))\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            z: a float tensor with shape [b, n, d].\n",
        "        Returns:\n",
        "            a float tensor with shape [b, k, d].\n",
        "        \"\"\"\n",
        "        b = z.size(0)\n",
        "        s = self.seed_vectors\n",
        "        s = s.repeat([b, 1, 1])  # random seed vector: shape [b, k, d]\n",
        "\n",
        "        output = self.mab(s, z)\n",
        "        # print('PoolingMultiheadAttention', output.shape)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "nXmj0XXkq-s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set transformer for ingredient representation\n",
        "class SetTransformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            in_dimension: an integer.  # 2\n",
        "            out_dimension: an integer. # 5 * K\n",
        "        \"\"\"\n",
        "        super(SetTransformer, self).__init__()\n",
        "        in_dimension = 46 # 300\n",
        "        out_dimension = 128 # 600\n",
        "\n",
        "        d = in_dimension\n",
        "        m = 46  # number of inducing points\n",
        "        h = 2  # 4 # number of heads\n",
        "        k = 4  # number of seed vectors\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            InducedSetAttentionBlock(d, m, h, RFF(d), RFF(d)),\n",
        "            InducedSetAttentionBlock(d, m, h, RFF(d), RFF(d))\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            PoolingMultiheadAttention(d, k, h, RFF(d)),\n",
        "            SetAttentionBlock(d, h, RFF(d))\n",
        "        )\n",
        "\n",
        "        self.decoder_2 = nn.Sequential(\n",
        "            PoolingMultiheadAttention(d, k, h, RFF(d))\n",
        "        )\n",
        "        self.decoder_3 = nn.Sequential(\n",
        "            SetAttentionBlock(d, h, RFF(d))\n",
        "        )\n",
        "\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.Linear(k * d, out_dimension),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: a float tensor with shape [batch, n, in_dimension].\n",
        "        Returns:\n",
        "            a float tensor with shape [batch, out_dimension].\n",
        "        \"\"\"\n",
        "        x = self.encoder(x) # x = self.encoder(cut_x) # shape [batch, batch_max_len, d]\n",
        "        x = self.dropout(x)\n",
        "        x = self.decoder(x)  # shape [batch, k, d]\n",
        "\n",
        "        b, k, d = x.shape\n",
        "        x = x.view(b, k * d)\n",
        "\n",
        "        y = self.predictor(x)\n",
        "        return y"
      ],
      "metadata": {
        "id": "zUxG4z89rC4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN"
      ],
      "metadata": {
        "id": "DAvfLU28rGuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class custom_HeteroGraphConv(nn.Module):\n",
        "    def __init__(self, mods, aggregate='sum'):\n",
        "        super(custom_HeteroGraphConv, self).__init__()\n",
        "        self.mods = nn.ModuleDict(mods)\n",
        "        # Do not break if graph has 0-in-degree nodes.\n",
        "        # Because there is no general rule to add self-loop for heterograph.\n",
        "        for _, v in self.mods.items():\n",
        "            set_allow_zero_in_degree_fn = getattr(v, 'set_allow_zero_in_degree', None)\n",
        "            if callable(set_allow_zero_in_degree_fn):\n",
        "                set_allow_zero_in_degree_fn(True)\n",
        "        if isinstance(aggregate, str):\n",
        "            self.agg_fn = get_aggregate_fn(aggregate)\n",
        "        else:\n",
        "            self.agg_fn = aggregate\n",
        "\n",
        "    def forward(self, g, inputs, mod_args=None, mod_kwargs=None):\n",
        "        if mod_args is None:\n",
        "            mod_args = {}\n",
        "        if mod_kwargs is None:\n",
        "            mod_kwargs = {}\n",
        "        outputs = {nty : [] for nty in g.dsttypes}\n",
        "        if isinstance(inputs, tuple) or g.is_block:\n",
        "            if isinstance(inputs, tuple):\n",
        "                src_inputs, dst_inputs = inputs\n",
        "            else:\n",
        "                src_inputs = inputs\n",
        "                dst_inputs = {k: v[:g.number_of_dst_nodes(k)] for k, v in inputs.items()}\n",
        "\n",
        "            for stype, etype, dtype in g.canonical_etypes:\n",
        "                rel_graph = g[stype, etype, dtype]\n",
        "                if rel_graph.number_of_edges() == 0:\n",
        "                    continue\n",
        "                if stype not in src_inputs or dtype not in dst_inputs:\n",
        "                    continue\n",
        "                dstdata = self.mods[etype](\n",
        "                    rel_graph,\n",
        "                    (src_inputs[stype], dst_inputs[dtype], mod_kwargs),\n",
        "                    *mod_args.get(etype, ())\n",
        "                    )\n",
        "                outputs[dtype].append(dstdata)\n",
        "        else:\n",
        "            for stype, etype, dtype in g.canonical_etypes:\n",
        "                rel_graph = g[stype, etype, dtype]\n",
        "                if rel_graph.number_of_edges() == 0:\n",
        "                    continue\n",
        "                if stype not in inputs:\n",
        "                    continue\n",
        "                dstdata = self.mods[etype](\n",
        "                    rel_graph,\n",
        "                    (inputs[stype], inputs[dtype], mod_kwargs),\n",
        "                    *mod_args.get(etype, ())\n",
        "                    )\n",
        "                outputs[dtype].append(dstdata)\n",
        "        rsts = {}\n",
        "        for nty, alist in outputs.items():\n",
        "            if len(alist) != 0:\n",
        "                rsts[nty] = self.agg_fn(alist, nty)\n",
        "        return rsts\n",
        "\n",
        "def _max_reduce_func(inputs, dim):\n",
        "    return torch.max(inputs, dim=dim)[0]\n",
        "\n",
        "def _min_reduce_func(inputs, dim):\n",
        "    return torch.min(inputs, dim=dim)[0]\n",
        "\n",
        "def _sum_reduce_func(inputs, dim):\n",
        "    return torch.sum(inputs, dim=dim)\n",
        "\n",
        "def _mean_reduce_func(inputs, dim):\n",
        "    return torch.mean(inputs, dim=dim)\n",
        "\n",
        "def _stack_agg_func(inputs, dsttype):\n",
        "    if len(inputs) == 0:\n",
        "        return None\n",
        "    return torch.stack(inputs, dim=1)\n",
        "\n",
        "def _agg_func(inputs, dsttype, fn):\n",
        "    if len(inputs) == 0:\n",
        "        return None\n",
        "    stacked = torch.stack(inputs, dim=0)\n",
        "    return fn(stacked, dim=0)\n",
        "\n",
        "def get_aggregate_fn(agg):\n",
        "    if agg == 'sum':\n",
        "        fn = _sum_reduce_func\n",
        "    elif agg == 'max':\n",
        "        fn = _max_reduce_func\n",
        "    elif agg == 'min':\n",
        "        fn = _min_reduce_func\n",
        "    elif agg == 'mean':\n",
        "        fn = _mean_reduce_func\n",
        "    elif agg == 'stack':\n",
        "        fn = None  # will not be called\n",
        "    else:\n",
        "        raise DGLError('Invalid cross type aggregator. Must be one of '\n",
        "                       '\"sum\", \"max\", \"min\", \"mean\" or \"stack\". But got \"%s\"' % agg)\n",
        "    if agg == 'stack':\n",
        "        return _stack_agg_func\n",
        "    else:\n",
        "        return partial(_agg_func, fn=fn)"
      ],
      "metadata": {
        "id": "YbCm1Y9zrFcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScorePredictor(nn.Module):\n",
        "    def forward(self, edge_subgraph, x):\n",
        "        with edge_subgraph.local_scope():\n",
        "            edge_subgraph.ndata['x'] = x\n",
        "            edge_subgraph.apply_edges(dgl.function.u_dot_v('x', 'x', 'score'), etype='u-r')\n",
        "            return edge_subgraph.edata['score'][('user', 'u-r', 'recipe')].squeeze()\n",
        "\n",
        "\n",
        "class RelationAttention(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size=16):\n",
        "        super(RelationAttention, self).__init__()\n",
        "\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Linear(in_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        w = self.project(z).mean(0)                    # (M, 1)\n",
        "        beta = torch.softmax(w, dim=0)                 # (M, 1)\n",
        "        beta = beta.expand((z.shape[0],) + beta.shape) # (N, M, 1)\n",
        "        out = (beta * z).sum(1)                        # (N, D * K)\n",
        "        return out\n",
        "\n",
        "def node_drop(feats, drop_rate, training):\n",
        "    n = feats.shape[0]\n",
        "    drop_rates = torch.FloatTensor(np.ones(n) * drop_rate)\n",
        "\n",
        "    if training:\n",
        "        masks = torch.bernoulli(1. - drop_rates).unsqueeze(1)\n",
        "        feats = masks.to(feats.device) * feats / (1. - drop_rate)\n",
        "    else:\n",
        "        feats = feats\n",
        "    return feats\n",
        "\n",
        "\n",
        "class custom_GATConv(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_feats,\n",
        "                 out_feats,\n",
        "                 num_heads,\n",
        "                 feat_drop=0.1,\n",
        "                 attn_drop=0.,\n",
        "                 negative_slope=0.2,\n",
        "                 edge_drop=0.1,\n",
        "                 residual=False,\n",
        "                 activation=None,\n",
        "                 allow_zero_in_degree=False,\n",
        "                 bias=True):\n",
        "        super(custom_GATConv, self).__init__()\n",
        "        self._num_heads = num_heads\n",
        "        self._in_src_feats, self._in_dst_feats = expand_as_pair(in_feats)\n",
        "        self._out_feats = out_feats\n",
        "        self._allow_zero_in_degree = allow_zero_in_degree\n",
        "        if isinstance(in_feats, tuple):\n",
        "            self.fc_src = nn.Linear(\n",
        "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
        "            self.fc_dst = nn.Linear(\n",
        "                self._in_dst_feats, out_feats * num_heads, bias=False)\n",
        "            self.fc_src2 = nn.Linear(\n",
        "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
        "            self.fc_dst2 = nn.Linear(\n",
        "                self._in_dst_feats, out_feats * num_heads, bias=False)\n",
        "        else:\n",
        "            self.fc = nn.Linear(\n",
        "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
        "            self.fc2 = nn.Linear(\n",
        "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
        "        self.attn_l = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
        "        self.attn_r = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
        "        self.attn_l2 = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
        "        self.attn_r2 = nn.Parameter(torch.FloatTensor(size=(1, num_heads, out_feats)))\n",
        "        self.feat_drop = nn.Dropout(feat_drop)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope)\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.FloatTensor(size=(num_heads * out_feats,)))\n",
        "        else:\n",
        "            self.register_buffer('bias', None)\n",
        "        if residual:\n",
        "            if self._in_dst_feats != out_feats:\n",
        "                self.res_fc = nn.Linear(\n",
        "                    self._in_dst_feats, num_heads * out_feats, bias=False)\n",
        "            else:\n",
        "                self.res_fc = Identity()\n",
        "        else:\n",
        "            self.register_buffer('res_fc', None)\n",
        "        self.reset_parameters()\n",
        "        self.activation = activation\n",
        "\n",
        "        self.edge_drop = edge_drop\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        gain = nn.init.calculate_gain('relu')\n",
        "        if hasattr(self, 'fc'):\n",
        "            nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
        "        else:\n",
        "            nn.init.xavier_normal_(self.fc_src.weight, gain=gain)\n",
        "            nn.init.xavier_normal_(self.fc_dst.weight, gain=gain)\n",
        "        nn.init.xavier_normal_(self.attn_l, gain=gain)\n",
        "        nn.init.xavier_normal_(self.attn_r, gain=gain)\n",
        "        nn.init.xavier_normal_(self.attn_l2, gain=gain)\n",
        "        nn.init.xavier_normal_(self.attn_r2, gain=gain)\n",
        "        nn.init.constant_(self.bias, 0)\n",
        "        if isinstance(self.res_fc, nn.Linear):\n",
        "            nn.init.xavier_normal_(self.res_fc.weight, gain=gain)\n",
        "\n",
        "    def set_allow_zero_in_degree(self, set_value):\n",
        "        self._allow_zero_in_degree = set_value\n",
        "\n",
        "    def forward(self, graph, feat, get_attention=False):\n",
        "        with graph.local_scope():\n",
        "            if not self._allow_zero_in_degree:\n",
        "                if (graph.in_degrees() == 0).any():\n",
        "                    raise DGLError('There are 0-in-degree nodes in the graph, '\n",
        "                                   'output for those nodes will be invalid. '\n",
        "                                   'This is harmful for some applications, '\n",
        "                                   'causing silent performance regression. '\n",
        "                                   'Adding self-loop on the input graph by '\n",
        "                                   'calling `g = dgl.add_self_loop(g)` will resolve '\n",
        "                                   'the issue. Setting ``allow_zero_in_degree`` '\n",
        "                                   'to be `True` when constructing this module will '\n",
        "                                   'suppress the check and let the code run.')\n",
        "\n",
        "            if isinstance(feat, tuple):\n",
        "                do_edge_drop = feat[2]\n",
        "                # print('do_edge_drop: ', do_edge_drop)\n",
        "                h_src = self.feat_drop(feat[0])\n",
        "                h_dst = self.feat_drop(feat[1])\n",
        "                h_src2 = h_src.clone()\n",
        "                h_dst2 = h_dst.clone()\n",
        "                if not hasattr(self, 'fc_src'):\n",
        "                    feat_src = self.fc(h_src).view(-1, self._num_heads, self._out_feats)\n",
        "                    feat_dst = self.fc(h_dst).view(-1, self._num_heads, self._out_feats)\n",
        "                    feat_src2 = self.fc2(h_src2).view(-1, self._num_heads, self._out_feats)\n",
        "                    feat_dst2 = self.fc2(h_dst2).view(-1, self._num_heads, self._out_feats)\n",
        "                else:\n",
        "                    feat_src = self.fc_src(h_src).view(-1, self._num_heads, self._out_feats)\n",
        "                    feat_dst = self.fc_dst(h_dst).view(-1, self._num_heads, self._out_feats)\n",
        "                    feat_src2 = self.fc_src2(h_src2).view(-1, self._num_heads, self._out_feats)\n",
        "                    feat_dst2 = self.fc_dst2(h_dst2).view(-1, self._num_heads, self._out_feats)\n",
        "            else:\n",
        "                h_src = h_dst = self.feat_drop(feat)\n",
        "                h_src2 = h_dst2 = h_src.clone() # self.feat_drop(feat)\n",
        "                feat_src = feat_dst = self.fc(h_src).view(\n",
        "                    -1, self._num_heads, self._out_feats)\n",
        "                feat_src2 = feat_dst2 = self.fc(h_src).view(\n",
        "                    -1, self._num_heads, self._out_feats)\n",
        "                if graph.is_block:\n",
        "                    feat_dst = feat_src[:graph.number_of_dst_nodes()]\n",
        "                    feat_dst2 = feat_src2[:graph.number_of_dst_nodes()]\n",
        "\n",
        "            el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1)\n",
        "            er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1)\n",
        "\n",
        "            graph.srcdata.update({'ft': feat_src, 'el': el, 'feat_src2': feat_src2})\n",
        "            graph.dstdata.update({'er': er, 'feat_dst2': feat_dst2})\n",
        "            # compute edge attention, el and er are a_l Wh_i and a_r Wh_j respectively.\n",
        "            graph.apply_edges(fn.u_add_v('el', 'er', 'e'))\n",
        "            e = self.leaky_relu(graph.edata.pop('e'))\n",
        "\n",
        "            # compute softmax, edge dropout\n",
        "            if self.training and do_edge_drop and self.edge_drop > 0:\n",
        "                perm = torch.randperm(graph.number_of_edges(), device=e.device)\n",
        "                bound = int(graph.number_of_edges() * self.edge_drop)\n",
        "                eids = perm[bound:]\n",
        "                graph.edata[\"a\"] = torch.zeros_like(e)\n",
        "                graph.edata[\"a\"][eids] = self.attn_drop(edge_softmax(graph, e[eids], eids=eids))\n",
        "            else:\n",
        "                graph.edata['a'] = self.attn_drop(edge_softmax(graph, e))\n",
        "\n",
        "            # message passing\n",
        "            graph.update_all(fn.u_mul_e('ft', 'a', 'm'),\n",
        "                             fn.sum('m', 'initial_ft'))\n",
        "            graph.update_all(fn.u_mul_v('feat_src2', 'feat_dst2', 'm2'),\n",
        "                             fn.sum('m2', 'add_ft'))\n",
        "            rst = graph.dstdata['initial_ft'] + graph.dstdata['add_ft']\n",
        "\n",
        "            # residual\n",
        "            if self.res_fc is not None:\n",
        "                resval = self.res_fc(h_dst).view(h_dst.shape[0], self._num_heads, self._out_feats)\n",
        "                rst = rst + resval\n",
        "            # bias\n",
        "            if self.bias is not None:\n",
        "                rst = rst + self.bias.view(1, self._num_heads, self._out_feats)\n",
        "            # activation\n",
        "            if self.activation:\n",
        "                rst = self.activation(rst)\n",
        "\n",
        "            if get_attention:\n",
        "                return rst, graph.edata['a']\n",
        "            else:\n",
        "                return rst\n",
        "\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_heads = 4 # 8\n",
        "        self.hid_feats = int(hid_feats/self.num_heads)\n",
        "        self.out_feats = int(out_feats/self.num_heads)\n",
        "        self.relation_attention = RelationAttention(hid_feats)\n",
        "\n",
        "        self.gatconv1 = custom_HeteroGraphConv({ # dglnn.HeteroGraphConv\n",
        "            'i-r': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
        "            'r-i': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
        "            'r-r': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
        "            'i-i': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
        "            'u-r': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
        "            'r-u': custom_GATConv(in_feats, self.hid_feats, num_heads=self.num_heads),\n",
        "            }, aggregate='stack')\n",
        "\n",
        "        self.gatconv2 = custom_HeteroGraphConv({ # dglnn.HeteroGraphConv\n",
        "            'i-r': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
        "            'r-i': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
        "            'r-r': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
        "            'i-i': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
        "            'u-r': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
        "            'r-u': custom_GATConv(self.hid_feats*self.num_heads, self.out_feats, num_heads=self.num_heads),\n",
        "            }, aggregate='stack')\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "\n",
        "    def forward(self, blocks, inputs, do_edge_drop):\n",
        "        edge_weight_0 = blocks[0].edata['weight']\n",
        "        edge_weight_1 = blocks[1].edata['weight']\n",
        "\n",
        "        num_users = blocks[-1].dstdata[dgl.NID]['user'].shape[0]\n",
        "        num_recipes = blocks[-1].dstdata[dgl.NID]['recipe'].shape[0]\n",
        "\n",
        "        h = self.gatconv1(blocks[0], inputs, edge_weight_0, do_edge_drop)\n",
        "        h = {k: F.relu(v).flatten(2) for k, v in h.items()}\n",
        "        h = {k: self.relation_attention(v) for k, v in h.items()}\n",
        "\n",
        "        first_layer_output = {}\n",
        "        first_layer_output['user'] = h['user'][:num_users]\n",
        "        first_layer_output['recipe'] = h['recipe'][:num_recipes]\n",
        "\n",
        "        h = {key: self.dropout(value) for key, value in h.items()}\n",
        "        h = self.gatconv2(blocks[-1], h, edge_weight_1, do_edge_drop)\n",
        "        last_ingre_and_instr = h['recipe'].flatten(2)\n",
        "        h = {k: self.relation_attention(v.flatten(2)) for k, v in h.items()}\n",
        "\n",
        "        return h\n",
        "\n",
        "#         # combine several layer embs as the final emb\n",
        "#         combined_output = {}\n",
        "#         combined_output['user'] = torch.cat([h['user'], first_layer_output['user']], dim=1)\n",
        "#         combined_output['recipe'] = torch.cat([h['recipe'], first_layer_output['recipe']], dim=1)\n",
        "#         combined_output['user'] = torch.add(h['user'], first_layer_output['user'])\n",
        "#         combined_output['recipe'] = torch.add(h['recipe'], first_layer_output['recipe'])\n",
        "#         return combined_output"
      ],
      "metadata": {
        "id": "E8U8rfMJrLGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Losses and helper functions"
      ],
      "metadata": {
        "id": "J8MG_mFYrP6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(input, p=1, dim=1, eps=1e-12):\n",
        "    return input / input.norm(p, dim, keepdim=True).clamp(min=eps).expand_as(input)\n",
        "\n",
        "def get_recommendation_loss(pos_score, neg_score):\n",
        "    n = pos_score.shape[0]\n",
        "    return (neg_score.view(n, -1) - pos_score.view(n, -1) + 1).clamp(min=0).mean()\n",
        "\n",
        "def get_contrastive_loss(x1, x2):\n",
        "    temperature = 0.07\n",
        "\n",
        "    # users\n",
        "    x1_user, x2_user = F.normalize(x1['user']), F.normalize(x2['user'])\n",
        "    pos_score_user = torch.mul(x1_user, x2_user).sum(dim=1)\n",
        "    pos_score_user = torch.exp(pos_score_user/temperature)\n",
        "\n",
        "    x2_user_neg = torch.flipud(x2_user)\n",
        "    ttl_score_user = torch.mul(x1_user, x2_user_neg).sum(dim=1)\n",
        "    ttl_score_user = pos_score_user + torch.exp(ttl_score_user/temperature)\n",
        "\n",
        "    contrastive_loss_user = - torch.log(pos_score_user/ttl_score_user).mean()\n",
        "    # print('contrastive_loss_user: ', contrastive_loss_user)\n",
        "    assert not math.isnan(contrastive_loss_user)\n",
        "\n",
        "\n",
        "    # recipes\n",
        "    x1_recipe, x2_recipe = F.normalize(x1['recipe']), F.normalize(x2['recipe'])\n",
        "    pos_score_recipe = torch.mul(x1_recipe, x2_recipe).sum(dim=1)\n",
        "    pos_score_recipe = torch.exp(pos_score_recipe/temperature)\n",
        "\n",
        "    x2_recipe_neg = torch.flipud(x2_recipe)\n",
        "    ttl_score_recipe = torch.mul(x1_recipe, x2_recipe_neg).sum(dim=1)\n",
        "    ttl_score_recipe = pos_score_recipe + torch.exp(ttl_score_recipe/temperature) #.sum(dim=1)\n",
        "\n",
        "    contrastive_loss_recipe = - torch.log(pos_score_recipe/ttl_score_recipe).mean()\n",
        "    # print('contrastive_loss_recipe: ', contrastive_loss_recipe)\n",
        "\n",
        "    return contrastive_loss_user + contrastive_loss_recipe\n",
        "\n",
        "def get_emb_loss(*params):\n",
        "    out = None\n",
        "    for param in params:\n",
        "        for k,v in param.items():\n",
        "            if out == None:\n",
        "                out = (v**2/2).mean()\n",
        "            else:\n",
        "                out += (v**2/2).mean()\n",
        "    return out"
      ],
      "metadata": {
        "id": "9lbIW-lRrSvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "1QcxmKBOrV4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.user_embedding = nn.Sequential(\n",
        "            nn.Linear(300, 128),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.instr_embedding = nn.Sequential(\n",
        "            nn.Linear(1024, 128),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.ingredient_embedding = nn.Sequential(\n",
        "            nn.Linear(46, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.recipe_combine2out = nn.Sequential(\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.gnn = GNN(128, 128, 128, graph.etypes)\n",
        "        self.pred = ScorePredictor()\n",
        "        self.setTransformer_ = SetTransformer()\n",
        "\n",
        "    def forward(self, positive_graph, negative_graph, blocks, input_features):\n",
        "        user, instr, ingredient, ingredient_of_dst_recipe = input_features\n",
        "\n",
        "        # major GNN\n",
        "        user_major = self.user_embedding(user)\n",
        "        user_major = norm(user_major)\n",
        "        instr_major = self.instr_embedding(instr)\n",
        "        instr_major = norm(instr_major)\n",
        "        ingredient_major = self.ingredient_embedding(ingredient)\n",
        "        ingredient_major = norm(ingredient_major)\n",
        "        x = self.gnn(blocks, {'user': user_major, 'recipe': instr_major, 'ingredient': ingredient_major}, torch.Tensor([[0]]))\n",
        "\n",
        "        # contrastive - 1\n",
        "        user1 = node_drop(user, 0.1, model.training)\n",
        "        instr1 = node_drop(instr, 0.1, model.training)\n",
        "        ingredient1 = node_drop(ingredient, 0.1, model.training)\n",
        "\n",
        "        user1 = self.user_embedding(user1)\n",
        "        user1 = norm(user1)\n",
        "        instr1 = self.instr_embedding(instr1)\n",
        "        instr1 = norm(instr1)\n",
        "        ingredient1 = self.ingredient_embedding(ingredient1)\n",
        "        ingredient1 = norm(ingredient1)\n",
        "\n",
        "        x1 = self.gnn(blocks, {'user': user1, 'recipe': instr1, 'ingredient': ingredient1}, torch.Tensor([[1]]))\n",
        "\n",
        "        # contrastive - 2\n",
        "        user2 = node_drop(user, 0.1, model.training)\n",
        "        instr2 = node_drop(instr, 0.1, model.training)\n",
        "        ingredient2 = node_drop(ingredient, 0.1, model.training)\n",
        "\n",
        "        user2 = self.user_embedding(user2)\n",
        "        user2 = norm(user2)\n",
        "        instr2 = self.instr_embedding(instr2)\n",
        "        instr2 = norm(instr2)\n",
        "        ingredient2 = self.ingredient_embedding(ingredient2)\n",
        "        ingredient2 = norm(ingredient2)\n",
        "\n",
        "        x2 = self.gnn(blocks, {'user': user2, 'recipe': instr2, 'ingredient': ingredient2}, torch.Tensor([[1]]))\n",
        "\n",
        "        # setTransformer\n",
        "        all_ingre_emb_for_each_recipe = get_ingredient_neighbors_all_embeddings(blocks, blocks[1].dstdata['_ID']['recipe'], ingredient_of_dst_recipe)\n",
        "        all_ingre_emb_for_each_recipe = norm(all_ingre_emb_for_each_recipe)\n",
        "        total_ingre_emb = self.setTransformer_(all_ingre_emb_for_each_recipe) # 1\n",
        "        total_ingre_emb = norm(total_ingre_emb)\n",
        "\n",
        "        # scores\n",
        "        x['recipe'] = self.recipe_combine2out(total_ingre_emb.add(x['recipe']))\n",
        "        pos_score = self.pred(positive_graph, x)\n",
        "        neg_score = self.pred(negative_graph, x)\n",
        "\n",
        "        return pos_score, neg_score, x1, x2"
      ],
      "metadata": {
        "id": "oi0odx02rXhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics and evaluation methods"
      ],
      "metadata": {
        "id": "AwWUKySara9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
        "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cpu().numpy()\n",
        "    return roc_auc_score(labels, scores)\n",
        "\n",
        "def precision_at_k(r, k):\n",
        "    # Relevance is binary (nonzero is relevant).\n",
        "    assert k >= 1\n",
        "    r = np.asarray(r)[:k]\n",
        "    return np.mean(r)\n",
        "\n",
        "def recall_at_k(r, k, all_pos_num):\n",
        "    r = np.asfarray(r)[:k]\n",
        "    return np.sum(r) / all_pos_num\n",
        "\n",
        "def dcg_at_k(r, k, method=0):\n",
        "    # method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "    #         If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "    r = np.asfarray(r)[:k]\n",
        "    if r.size:\n",
        "        if method == 0:\n",
        "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
        "        elif method == 1:\n",
        "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
        "        else:\n",
        "            raise ValueError('method must be 0 or 1.')\n",
        "    return 0.\n",
        "\n",
        "def ndcg_at_k(r, k, method=0):\n",
        "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    return dcg_at_k(r, k, method) / dcg_max\n",
        "\n",
        "\n",
        "def average_precision_at_k(r, Ks):\n",
        "    r = np.asarray(r) != 0\n",
        "    out = []\n",
        "    for k in Ks:\n",
        "        assert k <= len(r)\n",
        "        # print('[precision_at_k(r, i + 1) for i in range(k) if r[i]]: ', [precision_at_k(r, i + 1) for i in range(k) if r[i]])\n",
        "        all_precision_before_k = [precision_at_k(r, i + 1) for i in range(k) if r[i]]\n",
        "        if len(all_precision_before_k) == 0:\n",
        "            all_precision_before_k = [0]\n",
        "        out.append(np.mean(all_precision_before_k))\n",
        "    if not out:\n",
        "        return 0.\n",
        "    # return np.array([np.mean(out)])\n",
        "    return np.array(out)\n",
        "\n",
        "def get_map_at_k(rs, Ks):\n",
        "    # examples:\n",
        "    # average_precision_at_k([1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [5,10])\n",
        "    # average_precision_at_k([0, 0, 1, 0, 0, 0, 0, 0, 0, 1], [5,10])\n",
        "    # get_map_at_k([[1, 1, 0, 1, 0, 1, 0, 0, 0, 1,1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1,1]], [5,10])\n",
        "    out = np.zeros(len(Ks))\n",
        "    for r in rs:\n",
        "        # print('average_precision_at_k: ', average_precision_at_k(r, Ks))\n",
        "        out += average_precision_at_k(r, Ks)/len(rs)\n",
        "    return out\n",
        "    # return np.mean([average_precision(r) for r in rs])\n",
        "\n",
        "def get_ranklist_for_one_user(user_poss, user_negs, Ks):\n",
        "    item_scores = {}\n",
        "    n_pos = len(user_poss)\n",
        "    n_neg = len(user_negs)\n",
        "    for i in range(n_pos):\n",
        "        item_scores[i] = user_poss[i]\n",
        "    for i in range(n_neg):\n",
        "        item_scores[i+1] = user_negs[i]\n",
        "\n",
        "    K_max = max(Ks)\n",
        "    K_max_item_score = heapq.nlargest(K_max, item_scores, key=item_scores.get)\n",
        "\n",
        "    r = []\n",
        "    for i in K_max_item_score:\n",
        "        if i < n_pos:\n",
        "            r.append(1)\n",
        "        else:\n",
        "            r.append(0)\n",
        "    return r\n",
        "\n",
        "def hit_at_k(r, k):\n",
        "    r = np.array(r)[:k]\n",
        "    if np.sum(r) > 0:\n",
        "        return 1.\n",
        "    else:\n",
        "        return 0.\n",
        "\n",
        "def get_mrr(rs):\n",
        "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
        "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
        "\n",
        "\n",
        "def get_performance_one_user(user_poss, user_negs, Ks):\n",
        "    r = get_ranklist_for_one_user(user_poss, user_negs, Ks)\n",
        "\n",
        "    precision, recall, ndcg, hit_ratio = [], [], [], []\n",
        "    for K in Ks:\n",
        "        precision.append(precision_at_k(r, K))\n",
        "        # recall.append(recall_at_k(r, K, len(user_poss)))\n",
        "        ndcg.append(ndcg_at_k(r, K))\n",
        "        hit_ratio.append(hit_at_k(r, K))\n",
        "    # return {'precision': np.array(precision), 'recall': np.array(recall),\n",
        "    #         'ndcg': np.array(ndcg), 'hit_ratio': np.array(hit_ratio)}, r\n",
        "    return {'precision': np.array(precision),\n",
        "            'ndcg': np.array(ndcg), 'hit_ratio': np.array(hit_ratio)}, r\n",
        "\n",
        "\n",
        "def get_performance_all_users(user2pos_score_dict, user2neg_score_dict, Ks):\n",
        "    # all_result = {'precision': np.zeros(len(Ks)), 'recall': np.zeros(len(Ks)), 'ndcg': np.zeros(len(Ks)),\n",
        "    #           'hit_ratio': np.zeros(len(Ks))}\n",
        "    all_result = {'hit_ratio': np.zeros(len(Ks)), 'ndcg': np.zeros(len(Ks)), 'precision': np.zeros(len(Ks))}\n",
        "\n",
        "    rs = []\n",
        "    n_test_users = len(user2pos_score_dict)\n",
        "\n",
        "    # one specific user\n",
        "    for user in user2pos_score_dict.keys():\n",
        "        user_pos_score = user2pos_score_dict[user]\n",
        "        user_neg_score = user2neg_score_dict[user]\n",
        "        one_result, one_r = get_performance_one_user(user_pos_score, user_neg_score, Ks)\n",
        "        # all_result['recall'] += one_result['recall']/n_test_users\n",
        "        all_result['hit_ratio'] += one_result['hit_ratio']/n_test_users\n",
        "        all_result['ndcg'] += one_result['ndcg']/n_test_users\n",
        "        all_result['precision'] += one_result['precision']/n_test_users\n",
        "        rs.append(one_r)\n",
        "\n",
        "    # get MRR\n",
        "    # MRR = get_mrr(rs)\n",
        "    # all_result['MRR'] = MRR\n",
        "\n",
        "    # get MAP\n",
        "    MAP = get_map_at_k(rs, Ks)\n",
        "    all_result['MAP'] = MAP\n",
        "\n",
        "    return all_result\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, multi_metrics=False):\n",
        "    # print('start evaluating ...')\n",
        "    evaluate_start = time.time()\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    epoch_contrastive_loss = 0\n",
        "    iteration_cnt = 0\n",
        "    total_pos_score = torch.tensor([]).to(device)\n",
        "    total_neg_score = torch.tensor([]).to(device)\n",
        "\n",
        "    # for evaluation\n",
        "    user2pos_score_dict = {}\n",
        "    user2neg_score_dict = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_nodes, positive_graph, negative_graph, blocks in dataloader:\n",
        "            blocks = [b.to(device) for b in blocks]\n",
        "            positive_graph = positive_graph.to(device)\n",
        "            negative_graph = negative_graph.to(device)\n",
        "\n",
        "            input_user = blocks[0].srcdata['random_feature']['user']\n",
        "            input_instr = blocks[0].srcdata['avg_instr_feature']['recipe']\n",
        "            input_ingredient = blocks[0].srcdata['nutrient_feature']['ingredient']\n",
        "            ingredient_of_dst_recipe = blocks[1].srcdata['nutrient_feature']['ingredient']\n",
        "            input_features = [input_user, input_instr, input_ingredient, ingredient_of_dst_recipe]\n",
        "\n",
        "            pos_score, neg_score, x1, x2 = model(positive_graph, negative_graph, blocks, input_features)\n",
        "            contrastive_loss = get_contrastive_loss(x1, x2)\n",
        "            total_pos_score = torch.cat([total_pos_score, pos_score])\n",
        "            total_neg_score = torch.cat([total_neg_score, neg_score])\n",
        "\n",
        "            recommendation_loss = get_recommendation_loss(pos_score, neg_score)\n",
        "            loss = recommendation_loss # + 0.01 * contrastive_loss\n",
        "            total_loss += recommendation_loss.item()\n",
        "            epoch_contrastive_loss += contrastive_loss.item()\n",
        "            iteration_cnt += 1\n",
        "\n",
        "            # for evaluation\n",
        "            global_test_users = blocks[1].dstdata['_ID']['user'] # we need to map the user id in subgraph to the whole graph\n",
        "            test_users, test_recipes = positive_graph.edges(etype='u-r')\n",
        "            test_users = test_users.tolist()\n",
        "            test_recipes = test_recipes.tolist()\n",
        "            for index in range(len(test_users)):\n",
        "                test_u = int(global_test_users[test_users[index]])\n",
        "                test_r = int(test_recipes[index])\n",
        "                test_score = float(pos_score[index])\n",
        "\n",
        "                if test_u not in user2pos_score_dict:\n",
        "                    user2pos_score_dict[test_u] = []\n",
        "                user2pos_score_dict[test_u].append(test_score)\n",
        "\n",
        "                if test_u not in user2neg_score_dict:\n",
        "                    user2neg_score_dict[test_u] = neg_score[index*n_test_negs:(index+1)*n_test_negs]\n",
        "\n",
        "            # break\n",
        "\n",
        "        total_loss /= iteration_cnt\n",
        "        epoch_contrastive_loss /= iteration_cnt\n",
        "\n",
        "        # metrics\n",
        "        auc = compute_auc(total_pos_score, total_neg_score)\n",
        "        if multi_metrics:\n",
        "            # evaluation_result = get_performance_all_users(total_pos_score, total_neg_score, Ks)\n",
        "            evaluation_result = get_performance_all_users(user2pos_score_dict, user2neg_score_dict, Ks)\n",
        "            evaluation_result['AUC'] = auc\n",
        "            print('evaluation_result: ', evaluation_result)\n",
        "            print('epoch_contrastive_loss: ', epoch_contrastive_loss)\n",
        "        else:\n",
        "            print('AUC: ', auc)\n",
        "\n",
        "        evalutate_time = time.strftime(\"%M:%S min\", time.gmtime(time.time()-evaluate_start))\n",
        "        print('evalutate_time: ', evalutate_time)\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "C3JY63BlrcwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "UY7L2R8MrgXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.9)\n",
        "\n",
        "print('start ... ')\n",
        "for epoch in range(50):\n",
        "    train_start = time.time()\n",
        "    epoch_loss = 0\n",
        "    epoch_contrastive_loss = 0\n",
        "    epoch_emb_loss = 0\n",
        "    iteration_cnt = 0\n",
        "\n",
        "    for input_nodes, positive_graph, negative_graph, blocks in train_edgeloader:\n",
        "        model.train()\n",
        "        blocks = [b.to(device) for b in blocks]\n",
        "        positive_graph = positive_graph.to(device)\n",
        "        negative_graph = negative_graph.to(device)\n",
        "\n",
        "        input_user = blocks[0].srcdata['random_feature']['user']\n",
        "        input_instr = blocks[0].srcdata['avg_instr_feature']['recipe']\n",
        "        input_ingredient = blocks[0].srcdata['nutrient_feature']['ingredient']\n",
        "        ingredient_of_dst_recipe = blocks[1].srcdata['nutrient_feature']['ingredient']\n",
        "        input_features = [input_user, input_instr, input_ingredient, ingredient_of_dst_recipe]\n",
        "\n",
        "        pos_score, neg_score, x1, x2 = model(positive_graph, negative_graph, blocks, input_features)\n",
        "        contrastive_loss = get_contrastive_loss(x1, x2)\n",
        "        # emb_loss = get_emb_loss(x1, x2)\n",
        "        assert not math.isnan(contrastive_loss)\n",
        "        recommendation_loss = get_recommendation_loss(pos_score, neg_score)\n",
        "        assert not math.isnan(recommendation_loss)\n",
        "\n",
        "        loss = recommendation_loss + 0.1 * contrastive_loss # + 1e-5 * emb_loss\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        epoch_loss += recommendation_loss.item()\n",
        "        epoch_contrastive_loss += contrastive_loss.item()\n",
        "        # epoch_emb_loss += emb_loss.item()\n",
        "        iteration_cnt += 1\n",
        "\n",
        "        # break\n",
        "\n",
        "    epoch_loss /= iteration_cnt\n",
        "    epoch_contrastive_loss /= iteration_cnt\n",
        "    train_end = time.strftime(\"%M:%S min\", time.gmtime(time.time()-train_start))\n",
        "\n",
        "    print('Epoch: {0},  Loss: {l:.4f}, Contrastive: {cl:.4f}, Emb: {el:.4f},  Time: {t}, LR: {lr:.6f}'\n",
        "          .format(epoch, l=epoch_loss, cl=epoch_contrastive_loss, el=epoch_emb_loss, t=train_end, lr=opt.param_groups[0]['lr']))\n",
        "    scheduler.step()\n",
        "\n",
        "    # Evaluation\n",
        "    # For demonstration purpose, only test set result is reported here. Please use val_dataloader for comprehensiveness.\n",
        "    if epoch >= 4 and epoch % 1 == 0:\n",
        "        print('testing: ')\n",
        "        evaluate(model, test_edgeloader, multi_metrics=True)\n",
        "        print()\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nDvIJiZvriCs",
        "outputId": "a322a21a-2852-4606-f919-84fe32b83c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start ... \n",
            "Epoch: 0,  Loss: 0.6383, Contrastive: 0.2247, Emb: 0.0000,  Time: 03:51 min, LR: 0.005000\n",
            "Epoch: 1,  Loss: 0.4799, Contrastive: 0.0617, Emb: 0.0000,  Time: 03:52 min, LR: 0.004500\n",
            "Epoch: 2,  Loss: 0.4433, Contrastive: 0.0460, Emb: 0.0000,  Time: 03:50 min, LR: 0.004050\n",
            "Epoch: 3,  Loss: 0.4208, Contrastive: 0.0361, Emb: 0.0000,  Time: 03:49 min, LR: 0.003645\n",
            "Epoch: 4,  Loss: 0.4016, Contrastive: 0.0289, Emb: 0.0000,  Time: 03:49 min, LR: 0.003281\n",
            "testing: \n",
            "evaluation_result:  {'hit_ratio': array([0.17728358, 0.22238975, 0.25731876, 0.28558864, 0.31385852,\n",
            "       0.34062068, 0.36348788, 0.386732  , 0.40909662, 0.42982787]), 'ndcg': array([0.17728358, 0.22238975, 0.2444275 , 0.25856244, 0.27073762,\n",
            "       0.28109063, 0.28923609, 0.29698413, 0.30403939, 0.31028011]), 'precision': array([0.17728358, 0.11119487, 0.08577292, 0.07139716, 0.0627717 ,\n",
            "       0.05677011, 0.05192684, 0.0483415 , 0.04545518, 0.04298279]), 'MAP': array([0.17728358, 0.19983666, 0.21147967, 0.21854714, 0.22420111,\n",
            "       0.22866147, 0.23192822, 0.23483373, 0.23731869, 0.23939181]), 'AUC': 0.7527082168395979}\n",
            "epoch_contrastive_loss:  0.024555650170123768\n",
            "evalutate_time:  04:40 min\n",
            "\n",
            "\n",
            "Epoch: 5,  Loss: 0.3883, Contrastive: 0.0257, Emb: 0.0000,  Time: 03:50 min, LR: 0.002952\n",
            "testing: \n",
            "evaluation_result:  {'hit_ratio': array([0.16497047, 0.21007664, 0.24864933, 0.28068853, 0.30971228,\n",
            "       0.33785651, 0.36273401, 0.38748587, 0.40796582, 0.43120995]), 'ndcg': array([0.16497047, 0.21007664, 0.2344133 , 0.2504329 , 0.26293275,\n",
            "       0.27382042, 0.28268197, 0.29093258, 0.29739329, 0.30439047]), 'precision': array([0.16497047, 0.10503832, 0.08288311, 0.07017213, 0.06194246,\n",
            "       0.05630942, 0.05181914, 0.04843573, 0.04532954, 0.043121  ]), 'MAP': array([0.16497047, 0.18752356, 0.20038112, 0.20839092, 0.21419567,\n",
            "       0.21888638, 0.2224403 , 0.22553429, 0.22780984, 0.23013425]), 'AUC': 0.753153821647288}\n",
            "epoch_contrastive_loss:  0.01921706557983444\n",
            "evalutate_time:  04:40 min\n",
            "\n",
            "\n",
            "Epoch: 6,  Loss: 0.3800, Contrastive: 0.0227, Emb: 0.0000,  Time: 03:49 min, LR: 0.002657\n",
            "testing: \n",
            "evaluation_result:  {'hit_ratio': array([0.17125267, 0.21560498, 0.25179043, 0.28596557, 0.31461239,\n",
            "       0.34024375, 0.36311094, 0.38861666, 0.40985048, 0.43234075]), 'ndcg': array([0.17125267, 0.21560498, 0.23843545, 0.25552303, 0.26786054,\n",
            "       0.2777761 , 0.28592156, 0.29442347, 0.30112199, 0.30789224]), 'precision': array([0.17125267, 0.10780249, 0.08393014, 0.07149139, 0.06292248,\n",
            "       0.05670729, 0.05187299, 0.04857708, 0.04553894, 0.04323407]), 'MAP': array([0.17125267, 0.19342882, 0.20549064, 0.21403443, 0.21976379,\n",
            "       0.22403568, 0.22730242, 0.23049064, 0.23284995, 0.23509898]), 'AUC': 0.7508266580952851}\n",
            "epoch_contrastive_loss:  0.018518097269984466\n",
            "evalutate_time:  04:40 min\n",
            "\n",
            "\n",
            "Epoch: 7,  Loss: 0.3724, Contrastive: 0.0219, Emb: 0.0000,  Time: 03:49 min, LR: 0.002391\n",
            "testing: \n",
            "evaluation_result:  {'hit_ratio': array([0.17313733, 0.21723835, 0.25832391, 0.29111697, 0.32252796,\n",
            "       0.3495414 , 0.37379068, 0.39753738, 0.41902249, 0.43899987]), 'ndcg': array([0.17313733, 0.21723835, 0.24316045, 0.25955698, 0.27308496,\n",
            "       0.28353518, 0.29217295, 0.30008852, 0.30686632, 0.31288011]), 'precision': array([0.17313733, 0.10861917, 0.08610797, 0.07277924, 0.06450559,\n",
            "       0.0582569 , 0.05339867, 0.04969217, 0.04655805, 0.04389999]), 'MAP': array([0.17313733, 0.19518784, 0.20888303, 0.21708129, 0.22336349,\n",
            "       0.22786573, 0.23132991, 0.23429825, 0.23668548, 0.23868322]), 'AUC': 0.7589758486454665}\n",
            "epoch_contrastive_loss:  0.016634427351019686\n",
            "evalutate_time:  04:38 min\n",
            "\n",
            "\n",
            "Epoch: 8,  Loss: 0.3644, Contrastive: 0.0200, Emb: 0.0000,  Time: 03:49 min, LR: 0.002152\n",
            "testing: \n",
            "evaluation_result:  {'hit_ratio': array([0.16873979, 0.21723835, 0.25304687, 0.28759894, 0.31574318,\n",
            "       0.34388742, 0.37341375, 0.39854253, 0.42480211, 0.44641287]), 'ndcg': array([0.16873979, 0.21723835, 0.23983101, 0.25710705, 0.26922811,\n",
            "       0.28011579, 0.29063328, 0.29900954, 0.30729351, 0.313799  ]), 'precision': array([0.16873979, 0.10861917, 0.08434896, 0.07189974, 0.06314864,\n",
            "       0.05731457, 0.05334482, 0.04981782, 0.04720023, 0.04464129]), 'MAP': array([0.16873979, 0.19298907, 0.20492524, 0.21356326, 0.21919211,\n",
            "       0.22388282, 0.22810086, 0.23124196, 0.23415969, 0.23632077]), 'AUC': 0.7576815815588123}\n",
            "epoch_contrastive_loss:  0.016438992014006962\n",
            "evalutate_time:  04:39 min\n",
            "\n",
            "\n",
            "Epoch: 9,  Loss: 0.3567, Contrastive: 0.0191, Emb: 0.0000,  Time: 03:49 min, LR: 0.001937\n",
            "testing: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-0601cebd984f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testing: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_edgeloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-5b2a0d73499f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, multi_metrics)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mpositive_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dgl/distributed/dist_dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collate_with_negative_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dgl/distributed/dist_dataloader.py\u001b[0m in \u001b[0;36m_collate_with_negative_sampling\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    710\u001b[0m         )\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         input_nodes, _, blocks = self.graph_sampler.sample_blocks(\n\u001b[0m\u001b[1;32m    713\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_sampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_eids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude_eids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dgl/dataloading/neighbor_sampler.py\u001b[0m in \u001b[0;36msample_blocks\u001b[0;34m(self, g, seed_nodes, exclude_eids)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfanout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfanouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     block = g.sample_neighbors_fused(\n\u001b[0m\u001b[1;32m    174\u001b[0m                         \u001b[0mseed_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                         \u001b[0mfanout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dgl/utils/internal.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[0m_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"Alias of :func:`dgl.{}`.\"\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dgl/sampling/neighbor.py\u001b[0m in \u001b[0;36msample_neighbors_fused\u001b[0;34m(g, nodes, fanout, edge_dir, prob, replace, copy_ndata, copy_edata, exclude_edges, mapping)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \"\"\"\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pinned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         frontier = _sample_neighbors(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dgl/sampling/neighbor.py\u001b[0m in \u001b[0;36m_sample_neighbors\u001b[0;34m(g, nodes, fanout, edge_dir, prob, replace, copy_ndata, copy_edata, _dist_training, exclude_edges, fused, mapping)\u001b[0m\n\u001b[1;32m    613\u001b[0m             ]\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         subgidx, induced_nodes, induced_edges = _CAPI_DGLSampleNeighborsFused(\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0mnodes_all_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}